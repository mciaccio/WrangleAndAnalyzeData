{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidy resolution  \n",
    "* messy data - structure issues  \n",
    "* Each variable forms a column  \n",
    "* Each observation forms a row  \n",
    "* Each type of observational unit forms a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 independent pandas DataFrames\n",
    "* pandas DataFrame\t- twitter_archive_common_df\n",
    "  * derived from twitter_archive_enhanced.csv (downloaded)  \n",
    "<br>\n",
    "* pandas DataFrame\t- image_common_df\n",
    "  * derived from image-predictions.tsv. (import requests)  \n",
    "<br>\n",
    "* pandas DataFrame\t- retrieved_tweet_data_df  \n",
    "  * derived from  (import tweepy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_common_df.shape\n",
      "(1981, 12)\n"
     ]
    }
   ],
   "source": [
    "# READ\n",
    "with open('image_common_df.pkl', 'rb') as f:\n",
    "    image_common_df = pickle.load(f)\n",
    "\n",
    "print('image_common_df.shape')\n",
    "print(image_common_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter_archive_common_df.shape\n",
      "(1981, 11)\n"
     ]
    }
   ],
   "source": [
    "# READ\n",
    "with open('twitter_archive_common_df.pkl', 'rb') as f:\n",
    "    twitter_archive_common_df = pickle.load(f) \n",
    "\n",
    "print('twitter_archive_common_df.shape')\n",
    "print(twitter_archive_common_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved_tweet_data_df.shape\n",
      "(1981, 3)\n"
     ]
    }
   ],
   "source": [
    "# READ\n",
    "with open('retrieved_tweet_data_df.pkl', 'rb') as f:\n",
    "    retrieved_tweet_data_df = pickle.load(f)\n",
    "\n",
    "print('retrieved_tweet_data_df.shape')\n",
    "print(retrieved_tweet_data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge\n",
    "* pandas DataFrame\t- twitter_archive_common_df\n",
    "  * derived from twitter_archive_enhanced.csv (downloaded)  \n",
    "<br>\n",
    "* pandas DataFrame\t- image_common_df\n",
    "  * derived from image-predictions.tsv. (import requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.merge(image_common_df, twitter_archive_common_df, \\\n",
    "        on='tweet_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merged DataFrame column count =  \n",
    "expected column count derived from merged entities  \n",
    "<br>\n",
    "merged pandas DataFrame Series, columns populated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(list(image_common_df.columns.values)) - 12\n",
      "\n",
      "len(list(twitter_archive_common_df.columns.values)) - 11\n",
      "\n",
      "len(list(merge1.columns.values)) - 22\n",
      "\n",
      "merge1.shape - (1981, 22)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1981 entries, 0 to 1980\n",
      "Data columns (total 22 columns):\n",
      "tweet_id                 1981 non-null object\n",
      "jpg_url                  1981 non-null object\n",
      "img_num                  1981 non-null int64\n",
      "p1                       1981 non-null object\n",
      "p1_conf                  1981 non-null float64\n",
      "p1_dog                   1981 non-null bool\n",
      "p2                       1981 non-null object\n",
      "p2_conf                  1981 non-null float64\n",
      "p2_dog                   1981 non-null bool\n",
      "p3                       1981 non-null object\n",
      "p3_conf                  1981 non-null float64\n",
      "p3_dog                   1981 non-null bool\n",
      "in_reply_to_status_id    22 non-null object\n",
      "in_reply_to_user_id      22 non-null object\n",
      "timestamp                1981 non-null datetime64[ns]\n",
      "source                   1981 non-null object\n",
      "text                     1981 non-null object\n",
      "expanded_urls            1981 non-null object\n",
      "rating_numerator         1981 non-null int64\n",
      "rating_denominator       1981 non-null int64\n",
      "name                     1981 non-null object\n",
      "maturity                 1981 non-null object\n",
      "dtypes: bool(3), datetime64[ns](1), float64(3), int64(3), object(12)\n",
      "memory usage: 315.3+ KB\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# column count for 1 of the 2 pd.merge inputs\n",
    "for column_name in list(image_common_df.columns.values):\n",
    "    # print('image_common_df - {}'.format(column_name))\n",
    "    pass\n",
    "print('len(list(image_common_df.columns.values)) - {}'.\\\n",
    "      format(len(list(image_common_df.columns.values))))\n",
    "\n",
    "print()\n",
    "\n",
    "# column count for 2 of the 2 pd.merge inputs\n",
    "for column_name in list(twitter_archive_common_df.columns.values):\n",
    "    # print('twitter_archive_common_df - {}'.format(column_name))\n",
    "    pass\n",
    "print('len(list(twitter_archive_common_df.columns.values)) - {}'.\\\n",
    "      format(len(list(twitter_archive_common_df.columns.values))))\n",
    "\n",
    "print()\n",
    "\n",
    "# column count for merge output\n",
    "# merge validation - Test\n",
    "for column_name in list(merge1.columns.values):\n",
    "    # print('merge1 - {}'.format(column_name))\n",
    "    pass\n",
    "print('len(list(merge1.columns.values)) - {}'.format(len(list(merge1.columns.values))))\n",
    "\n",
    "print()\n",
    "\n",
    "# merge output metrics - merge validation - Test\n",
    "print('merge1.shape - {}'.format(merge1.shape))\n",
    "\n",
    "# merge output metrics - merge validation - Test\n",
    "# pandas Series, columns populated post merge - Test\n",
    "print(merge1.info())\n",
    "print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge\n",
    "* pandas DataFrame\t- twitter_archive_common_df\n",
    "  * derived from twitter_archive_enhanced.csv (downloaded)  \n",
    "<br>\n",
    "* pandas DataFrame\t- image_common_df\n",
    "  * derived from image-predictions.tsv. (import requests)  \n",
    "<br>\n",
    "* pandas DataFrame\t- retrieved_tweet_data_df  \n",
    "  * derived from  (import tweepy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2 = pd.merge(merge1, retrieved_tweet_data_df, how='inner', \\\n",
    "         on='tweet_id',\n",
    "         left_index=True, right_index=True, sort=True,\\\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merged DataFrame column count =  \n",
    "expected column count derived from merged entities  \n",
    "<br>\n",
    "merged pandas DataFrame Series, columns populated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(list(merge1.columns.values)) - 22\n",
      "\n",
      "len(list(retrieved_tweet_data_df.columns.values)) - 3\n",
      "\n",
      "len(list(merge2.columns.values)) - 24\n",
      "\n",
      "merge1.shape - (1981, 22)\n",
      "retrieved_tweet_data_df.shape - (1981, 3)\n",
      "merge2.shape - (1981, 24)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1981 entries, 0 to 1980\n",
      "Data columns (total 24 columns):\n",
      "tweet_id                 1981 non-null object\n",
      "jpg_url                  1981 non-null object\n",
      "img_num                  1981 non-null int64\n",
      "p1                       1981 non-null object\n",
      "p1_conf                  1981 non-null float64\n",
      "p1_dog                   1981 non-null bool\n",
      "p2                       1981 non-null object\n",
      "p2_conf                  1981 non-null float64\n",
      "p2_dog                   1981 non-null bool\n",
      "p3                       1981 non-null object\n",
      "p3_conf                  1981 non-null float64\n",
      "p3_dog                   1981 non-null bool\n",
      "in_reply_to_status_id    22 non-null object\n",
      "in_reply_to_user_id      22 non-null object\n",
      "timestamp                1981 non-null datetime64[ns]\n",
      "source                   1981 non-null object\n",
      "text                     1981 non-null object\n",
      "expanded_urls            1981 non-null object\n",
      "rating_numerator         1981 non-null int64\n",
      "rating_denominator       1981 non-null int64\n",
      "name                     1981 non-null object\n",
      "maturity                 1981 non-null object\n",
      "retweet_count            1981 non-null object\n",
      "favorite_count           1981 non-null object\n",
      "dtypes: bool(3), datetime64[ns](1), float64(3), int64(3), object(14)\n",
      "memory usage: 426.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# column count for 1 of the 2 pd.merge inputs \n",
    "for column_name in list(merge1.columns.values):\n",
    "    # print('merge1 - {}'.format(column_name))\n",
    "    pass\n",
    "print('len(list(merge1.columns.values)) - {}'.\\\n",
    "      format(len(list(merge1.columns.values))))\n",
    "\n",
    "print()\n",
    "\n",
    "# column count for 2 of the 2 pd.merge inputs \n",
    "for column_name in list(retrieved_tweet_data_df.columns.values):\n",
    "    # print('retrieved_tweet_data_df - {}'.format(column_name))\n",
    "    pass\n",
    "print('len(list(retrieved_tweet_data_df.columns.values)) - {}'.\\\n",
    "      format(len(list(retrieved_tweet_data_df.columns.values))))\n",
    "\n",
    "print()\n",
    "\n",
    "# column count for merge output\n",
    "# merge validation - Test\n",
    "for column_name in list(merge2.columns.values):\n",
    "    # print('merge2 - {}'.format(column_name))\n",
    "    pass\n",
    "print('len(list(merge2.columns.values)) - {}'.\\\n",
    "      format(len(list(merge2.columns.values)))) \n",
    "\n",
    "print()\n",
    " \n",
    "# input to merge metrics, 1 of 2\n",
    "print('merge1.shape - {}'.format(merge1.shape))\n",
    "\n",
    "# input to merge metrics, 2 of 2\n",
    "print('retrieved_tweet_data_df.shape - {}'.format(retrieved_tweet_data_df.shape))\n",
    "print()\n",
    "\n",
    "# merge output metrics - merge validation - Test\n",
    "print('merge2.shape - {}'.format(merge2.shape))\n",
    "\n",
    "# merge output metrics - merge validation - Test\n",
    "# pandas Series, columns populated post merge - Test\n",
    "print(merge2.info()) \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirement identification  \n",
    "Data Analyst Nanodegree Program  \n",
    "8\\. Data Wrangling  \n",
    "Project: Wrangle and Analyze Data  \n",
    "3\\. Project Details\n",
    "\n",
    "Storing, Analyzing, and Visualizing Data for this Project  \n",
    "Store the clean DataFrame(s) in a CSV file with the main one named twitter_archive_master.csv.  \n",
    "If additional files exist because multiple tables are required for tidiness, name these files appropriately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter_archive_master.csv\n",
      "True\n",
      "\n",
      "image_common_master.csv\n",
      "True\n",
      "\n",
      "merge1_master.csv\n",
      "True\n",
      "\n",
      "retrieved_tweet_data_df_master.csv\n",
      "True\n",
      "\n",
      "merge2_master.csv\n",
      "True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_archive_common_df.to_csv\\\n",
    "('twitter_archive_master.csv', index = False)\n",
    "print('twitter_archive_master.csv')\n",
    "print(os.path.isfile('twitter_archive_master.csv') \\\n",
    "and os.path.getsize('twitter_archive_master.csv') > 0)\n",
    "print()\n",
    "\n",
    "image_common_df.to_csv('image_common_master.csv', index = False)\n",
    "print('image_common_master.csv')\n",
    "print(os.path.isfile('image_common_master.csv') \\\n",
    "and os.path.getsize('image_common_master.csv') > 0)\n",
    "print()\n",
    "\n",
    "merge1.to_csv('merge1_master.csv', index = False)\n",
    "print('merge1_master.csv')\n",
    "print(os.path.isfile('merge1_master.csv') \\\n",
    "and os.path.getsize('merge1_master.csv') > 0)\n",
    "print()\n",
    "\n",
    "retrieved_tweet_data_df.to_csv\\\n",
    "('retrieved_tweet_data_df_master.csv', index = False)\n",
    "print('retrieved_tweet_data_df_master.csv')\n",
    "print(os.path.isfile('retrieved_tweet_data_df_master.csv') \\\n",
    "and os.path.getsize('retrieved_tweet_data_df_master.csv') > 0)\n",
    "print()\n",
    "\n",
    "merge2.to_csv('merge2_master.csv', index = False)\n",
    "print('merge2_master.csv')\n",
    "print(os.path.isfile('merge2_master.csv') \\\n",
    "and os.path.getsize('merge2_master.csv') > 0)\n",
    "print() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge2.shape\n",
      "(1981, 24)\n"
     ]
    }
   ],
   "source": [
    "# Save merged DataFrame\n",
    "with open('merge2.pkl', 'wb') as f:\n",
    "    pickle.dump(merge2, f)\n",
    "    \n",
    "with open('merge2.pkl', 'rb') as f:\n",
    "    merge2 = pickle.load(f)\n",
    "    \n",
    "print('merge2.shape')\n",
    "print(merge2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
