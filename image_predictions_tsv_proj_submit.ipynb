{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import sys\n",
    "import urllib\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_predictions.tsv is hosted on Udacity's servers  \n",
    "Should be downloaded programmatically using the Requests library  \n",
    "URL: \n",
    "https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "url_list = url.split('/')\n",
    "image_predictions_file_name = url_list[-1]\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(image_predictions_file_name, mode='wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# production 2075 rows, obserations\n",
    "image_predictions_df = pd.read_csv('image-predictions.tsv', sep='\\t')\n",
    "\n",
    "image_predictions_df_clean = image_predictions_df.copy()\n",
    "image_predictions_df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tweet_id pandas series, column type - int64 not object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* change tweet_id pandas series, column from int64 to object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df_clean.tweet_id = \\\n",
    "image_predictions_df_clean.tweet_id.apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success\n",
    "* tweet_id pandas series, column no longer int64 changed to object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirement compliance  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analyst Nanodegree Program  \n",
    "8\\. Data Wrangling  \n",
    "Project  \n",
    "2\\. Project Motivation  \n",
    "Key Points  \n",
    "You only want original ratings ... that have images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some jpg_url(s) in image-predictions.tsv are unreachable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* identify and capture unreachable image_predictions_df_clean jpg_url(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# supports echoes during hour plus Jupyter cell run time\n",
    "break_count = 0\n",
    "\n",
    "# capture the invalid jpg_url(s) here\n",
    "bad_url_dictionary = {}\n",
    "\n",
    "# eventually we will clean, delete the rows, observations\n",
    "# with the invalid jpg_url(s).\n",
    "# first level set with the before DataFrame metrics\n",
    "print(\"image_predictions_df_clean.shape\")\n",
    "print(image_predictions_df_clean.shape)\n",
    "print()\n",
    "\n",
    "for index, row in image_predictions_df_clean.iterrows():\n",
    "    # supports spurious network exceptions management\n",
    "    attempts = 0 \n",
    "    \n",
    "    bad_url_list = []\n",
    "    break_count +=1\n",
    "    # print('row.tweet_id - {}'.format(row.tweet_id))\n",
    "    # print('row.jpg_url - {}'.format(row.jpg_url))\n",
    "\n",
    "    # while loop to mitigate spurious network issues\n",
    "    # see nested try except clauses\n",
    "    while attempts < 5:\n",
    "        try:\n",
    "            # troubleshooting development helper, again this takes an hour plus\n",
    "            if True:\n",
    "                x = urllib.request.urlopen(row.jpg_url, timeout = 20).getcode()\n",
    "                # print('x - {}\\n'.format(x))\n",
    "                # x - 200\n",
    "                # print('type(x) - {}\\n'.format(type(x)))\n",
    "                #        type(x) - <class 'int'>\n",
    "\n",
    "                # urllib.request.urlopen('https://pbs.twimg.com/media/CWDbv2yU4AARfeH.jpg').getcode()\n",
    "                # pass\n",
    "            break\n",
    "        except urllib.error.HTTPError:\n",
    "            # capture the invalid jpg_url(s)\n",
    "            bad_url_list.append(row.tweet_id)        \n",
    "            bad_url_list.append(row.jpg_url)  \n",
    "            bad_url_dictionary[index] = bad_url_list\n",
    "\n",
    "            print('HTTPError - sys.exc_info()')\n",
    "            print(sys.exc_info())\n",
    "            \n",
    "            print('index - {}'.format(index))\n",
    "            print('row.tweet_id - {}'.format(row.tweet_id))\n",
    "            print('row.jpg_url - {}'.format(row.jpg_url))\n",
    "            print()\n",
    "            break\n",
    "        except urllib.error.URLError:\n",
    "            # manage spurious network errors\n",
    "            attempts +=1\n",
    "            print('URLError - sys.exc_info()')\n",
    "            print(sys.exc_info())\n",
    "            \n",
    "            print('index - {}'.format(index))\n",
    "            print('row.tweet_id - {}'.format(row.tweet_id))\n",
    "            print('row.jpg_url - {}'.format(row.jpg_url))\n",
    "            print()\n",
    "            # mitigate spurious network issues\n",
    "            time.sleep(0.5)\n",
    "        except OSError:\n",
    "            # manage spurious network errors\n",
    "            attempts +=1 \n",
    "            print('OSError - sys.exc_info()')\n",
    "            print(sys.exc_info())\n",
    "            \n",
    "            print('index - {}'.format(index))\n",
    "            print('row.tweet_id - {}'.format(row.tweet_id))\n",
    "            print('row.jpg_url - {}'.format(row.jpg_url))\n",
    "            print()\n",
    "            # mitigate spurious network issues\n",
    "            time.sleep(0.5)\n",
    "        except:\n",
    "            # process takes 1 hour plus, facilitates running to completion\n",
    "            # if something missed - display it  \n",
    "            attempts +=1\n",
    "            print('except - sys.exc_info()')\n",
    "            print(sys.exc_info())\n",
    "            \n",
    "            print('index - {}'.format(index))\n",
    "            print('row.tweet_id - {}'.format(row.tweet_id))\n",
    "            print('row.jpg_url - {}'.format(row.jpg_url))\n",
    "            print()\n",
    "            # mitigate spurious network issues\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "    # mitigate spurious network issues\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # echo progress of hour plus Jupyter cell\n",
    "    if break_count % 100 == 0:\n",
    "        print('break_count - {}'.format(break_count))\n",
    "        # pass\n",
    "       \n",
    "    # facilitates development of hour plus Jupyter cell\n",
    "    # decrease 10000 during development\n",
    "    if break_count > 10000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verify unreachable image_predictions_df_clean jpg_url(s) captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bad_url_dictionary')\n",
    "print(bad_url_dictionary)\n",
    "print(len(bad_url_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# took hour(s) to generate the bad_url_dictionary\n",
    "# pickle write - save to file\n",
    "with open('bad_url_dictionary.pkl', 'wb') as filename:\n",
    "    pickle.dump(bad_url_dictionary, filename, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we can read it\n",
    "with open('bad_url_dictionary.pkl', 'rb') as filename:\n",
    "    bad_url_dictionary = pickle.load(filename)\n",
    "print('bad_url_dictionary')\n",
    "print(bad_url_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify we captured the unreachable urls\n",
    "for key, jpg_url in bad_url_dictionary.items():\n",
    "    print('tweet_id - {}'.format(jpg_url[0]))\n",
    "    print('\\tjpg_url - {}'.format(jpg_url[1]))\n",
    "\n",
    "    try:\n",
    "        code = urllib.request.urlopen(jpg_url[1], timeout = 20).getcode()\n",
    "        print('code - {}\\n'.format(code))\n",
    "    except urllib.error.HTTPError:\n",
    "        # print(sys.exc_info()[1]) \n",
    "        print('\\t{}\\n'.format(sys.exc_info()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success  \n",
    "definitively identified unreachable image_predictions_df_clean jpg_url(s) in the  \n",
    "programmatically downloaded image-predictions.tsv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* unreachable image-predictions.tsv jpg_url(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* remove rows, observations with unreachable image-predictions.tsv jpg_url(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"image_predictions_df_clean.shape\")\n",
    "print(image_predictions_df_clean.shape)\n",
    "print()\n",
    " \n",
    "for key, jpg_url in bad_url_dictionary.items():\n",
    "    print('tweet_id - {}'.format(jpg_url[0]))\n",
    "    print('\\tjpg_url - {}'.format(jpg_url[1]))\n",
    "    image_predictions_df_clean = \\\n",
    "    image_predictions_df_clean[image_predictions_df_clean.tweet_id != jpg_url[0]]\n",
    "\n",
    "print('image_predictions_df_clean.shape')\n",
    "print(image_predictions_df_clean.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "math works 2075 - 2072 - 3 rows removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* confirm unreachable image_predictions_df_clean jpg_url(s) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random hard coded positive control we should get this one    \n",
    "print(\"image_predictions_df_clean.loc[image_predictions_df_clean.tweet_id\\\n",
    "                               .isin(['837110210464448512'])]\")\n",
    "print(image_predictions_df_clean.loc[image_predictions_df_clean.tweet_id\\\n",
    "                               .isin(['837110210464448512'])])\n",
    "print()\n",
    "\n",
    "# We should not get any of these \n",
    "for key, jpg_url in bad_url_dictionary.items():\n",
    "    print('tweet_id - {}'.format(jpg_url[0]))\n",
    "    image_predictions_df_clean.loc[image_predictions_df_clean.tweet_id\\\n",
    "                               .isin([jpg_url[0]])]\n",
    "    # print('x - {}'.format(x))\n",
    "    # print('type(x) - {}\\n'.format(type(x)))\n",
    "    \n",
    "    print(image_predictions_df_clean.loc[image_predictions_df_clean.tweet_id\\\n",
    "                               .isin([jpg_url[0]])])\n",
    "    print()\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success\n",
    "* 3 rows, observations with unreachable jpg_url(s) removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned - image_predictions_df_clean\n",
    "with open('image_predictions_df_clean.pkl', 'wb') as f:\n",
    "    pickle.dump(image_predictions_df_clean, f)\n",
    "    \n",
    "# Read cleaned pandas DataFrame\n",
    "with open('image_predictions_df_clean.pkl', 'rb') as f:\n",
    "    image_predictions_df_clean = pickle.load(f)\n",
    "    \n",
    "# make sure we can read it\n",
    "print('image_predictions_df_clean.shape')\n",
    "print(image_predictions_df_clean.shape)\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
